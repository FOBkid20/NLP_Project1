{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import statistics\n",
    "import spacy\n",
    "import string\n",
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "import imdb\n",
    "from collections import Counter\n",
    "import collections\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# nltk.download('vader_lexicon')\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red carpet â€“ \n",
    "# For example, determine who was best dressed, worst dressed, most discussed, most controversial, \n",
    "# or perhaps find pictures of the best and worst dressed, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "gg_stop_words = ['HuffingtonPost','amp', 'Globe', 'RT', 'http', 'Golden', 'Globes', 'GoldenGlobes', 'Goldenglobes', 'Goldenglobe', 'gg','golden globes', 'golden globe', 'goldenglobe','goldenglobes','gg2015','gg15','goldenglobe2015','goldenglobe15','goldenglobes2015','goldenglobes15', 'gg2013','gg13','goldenglobe2013','goldenglobe13','goldenglobes2013','goldenglobes13', 'rt', '2013', '2015', '...', '`', 'MTVNews']\n",
    "\n",
    "rc_stop_words = ['eredcarpet', '\\'', 'lt', 'damn', '^']\n",
    "\n",
    "gg_stop_words.extend(stop_words)\n",
    "gg_stop_words.extend(rc_stop_words)\n",
    "\n",
    "tweets = json.load(open(\"gg2013.json\"))\n",
    "\n",
    "clean_tweets = []\n",
    "\n",
    "for tweet in tweets:\n",
    "    text = tweet['text']\n",
    "    text_tokens = word_tokenize(text)\n",
    "    t = []\n",
    "    sent = ''\n",
    "    for w in text_tokens:\n",
    "        if w.lower() not in gg_stop_words:\n",
    "            if w not in string.punctuation: \n",
    "                no_url = re.sub(r'(//t.co.*|`)', '', w) # remove urls\n",
    "                t.append(no_url)\n",
    "    for i in range(len(t)): \n",
    "        sent += t[i] + ' '\n",
    "    clean_tweets.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all red carpet tweets\n",
    "rc_tweets = []\n",
    "\n",
    "for t in clean_tweets:\n",
    "    if re.search(r'.*red.*carpet.*', t.lower()):\n",
    "        rc_tweets.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_w_sentiment = {}\n",
    "\n",
    "# for t in rc_tweets:\n",
    "#     score = SentimentIntensityAnalyzer().polarity_scores(t)['compound']\n",
    "#     if score != 0.0:\n",
    "#         tweets_w_sentiment[t] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(text):\n",
    "    article = nlp(text)\n",
    "    labels = [x.label_ for x in article.ents]\n",
    "    [(x.orth_,x.pos_, x.lemma_) for x in [y \n",
    "                                      for y\n",
    "                                      in nlp(text) \n",
    "                                      if not y.is_stop and y.pos_ != 'PUNCT']]\n",
    "    parts_of_speech = dict([(str(x), x.label_) for x in nlp(text).ents])\n",
    "    names = []\n",
    "    for (key, value) in parts_of_speech.items() :\n",
    "        if(value == \"PERSON\") :\n",
    "            names.append(key)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_dressed():\n",
    "    positive_sent = []\n",
    "    for t in rc_tweets:\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(t)['compound']\n",
    "        if score > 0.5:\n",
    "            positive_sent.append(t)\n",
    "    count = {}\n",
    "    for t in positive_sent: \n",
    "        names = get_names(t)\n",
    "        for name in names :\n",
    "            if len(name.split()) == 2:\n",
    "                if name in count :\n",
    "                    count[name] = count[name] + 1\n",
    "                else:\n",
    "                    count[name] = 1\n",
    "#     winner = max(count.items(), key=operator.itemgetter(1))[0]\n",
    "    winners = Counter(count).most_common(5)\n",
    "    result = []\n",
    "    for n in winners:\n",
    "        result.append(n[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zuhair Murad',\n",
       " 'Anne Hathaway',\n",
       " 'Jessica Chastain',\n",
       " 'Jennifer Lawrence',\n",
       " 'Taylor Swift']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worst_dressed():\n",
    "    \n",
    "    neg_words = ['bad', 'ugly', 'worst', 'awful', 'horrible', 'hate', 'suck', 'sucks', 'sucked', 'disappointing']\n",
    "    neg_sent = []\n",
    "    for t in rc_tweets:\n",
    "        if bool([ele for ele in neg_words if(ele in t)]):\n",
    "            neg_sent.append(t)\n",
    "    count = {}\n",
    "    \n",
    "    for t in neg_sent: \n",
    "        names = get_names(t)\n",
    "        for name in names :\n",
    "            if len(name.split()) == 2:\n",
    "                if name in count :\n",
    "                    count[name] = count[name] + 1\n",
    "                else:\n",
    "                    count[name] = 1\n",
    "#     winner = max(count.items(), key=operator.itemgetter(1))[0]\n",
    "    winners = Counter(count).most_common(5)\n",
    "    result = []\n",
    "    for n in winners:\n",
    "        result.append(n[0])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift', 'Kate Hudson', 'Amy Adams', 'Sally Fields', 'Lucy Liu']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worst_dressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_controversial():\n",
    "    best = best_dressed()\n",
    "    worst = worst_dressed()\n",
    "    controversial = []\n",
    "    for b in best:\n",
    "        for w in worst:\n",
    "            if b == w:\n",
    "                controversial.append(w)\n",
    "    return controversial\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taylor Swift']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_controversial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_discussed():\n",
    "    count = {}\n",
    "    names = []\n",
    "    for t in rc_tweets:\n",
    "        names = get_names(t)\n",
    "    for name in names :\n",
    "        if len(name.split()) == 2:\n",
    "            if name in count :\n",
    "                count[name] = count[name] + 1\n",
    "            else:\n",
    "                count[name] = 1\n",
    "    winner = max(count.items(), key=operator.itemgetter(1))[0]\n",
    "    return winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jennifer Lawrence'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_discussed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
